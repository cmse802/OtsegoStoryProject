{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from facebook_page_scraper import Facebook_scraper\n",
    "from facebook_page_scraper import driver_initialization\n",
    "from selenium.webdriver.common.by import By\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEB CONFIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'geckodriver' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/courses/cmse495/OtsegoStoryProject/.venv/lib/python3.13/site-packages/selenium/webdriver/common/service.py:71\u001b[39m, in \u001b[36mService.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     70\u001b[39m     cmd.extend(\u001b[38;5;28mself\u001b[39m.command_line_args())\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28mself\u001b[39m.process = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m=\u001b[49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mWindows\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mstdin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:1036\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1033\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1034\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1039\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1046\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:1966\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[39m\n\u001b[32m   1965\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1966\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[32m   1967\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/usr/local/bin/geckodriver'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mWebDriverException\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# options.add_argument(\"--headless\")  # Optional: Remove this line if you want to see the browser\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Start Selenium WebDriver manually\u001b[39;00m\n\u001b[32m     10\u001b[39m service = Service(GECKODRIVER_PATH)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m driver = \u001b[43mwebdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFirefox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mservice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/courses/cmse495/OtsegoStoryProject/.venv/lib/python3.13/site-packages/selenium/webdriver/firefox/webdriver.py:174\u001b[39m, in \u001b[36mWebDriver.__init__\u001b[39m\u001b[34m(self, firefox_profile, firefox_binary, capabilities, proxy, executable_path, options, service_log_path, service_args, service, desired_capabilities, log_path, keep_alive)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.service:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28mself\u001b[39m.service = Service(\n\u001b[32m    171\u001b[39m         executable_path,\n\u001b[32m    172\u001b[39m         service_args=service_args,\n\u001b[32m    173\u001b[39m         log_path=service_log_path)\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mservice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m executor = FirefoxRemoteConnection(\n\u001b[32m    177\u001b[39m     remote_server_addr=\u001b[38;5;28mself\u001b[39m.service.service_url,\n\u001b[32m    178\u001b[39m     ignore_proxy=options._ignore_local_proxy)\n\u001b[32m    179\u001b[39m RemoteWebDriver.\u001b[34m__init__\u001b[39m(\n\u001b[32m    180\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    181\u001b[39m     command_executor=executor,\n\u001b[32m    182\u001b[39m     options=options,\n\u001b[32m    183\u001b[39m     keep_alive=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/courses/cmse495/OtsegoStoryProject/.venv/lib/python3.13/site-packages/selenium/webdriver/common/service.py:81\u001b[39m, in \u001b[36mService.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m err.errno == errno.ENOENT:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m WebDriverException(\n\u001b[32m     82\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m executable needs to be in PATH. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % (\n\u001b[32m     83\u001b[39m                 os.path.basename(\u001b[38;5;28mself\u001b[39m.path), \u001b[38;5;28mself\u001b[39m.start_error_message)\n\u001b[32m     84\u001b[39m         )\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m err.errno == errno.EACCES:\n\u001b[32m     86\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m WebDriverException(\n\u001b[32m     87\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m executable may have wrong permissions. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % (\n\u001b[32m     88\u001b[39m                 os.path.basename(\u001b[38;5;28mself\u001b[39m.path), \u001b[38;5;28mself\u001b[39m.start_error_message)\n\u001b[32m     89\u001b[39m         )\n",
      "\u001b[31mWebDriverException\u001b[39m: Message: 'geckodriver' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home\n"
     ]
    }
   ],
   "source": [
    "# Specify the correct Geckodriver path\n",
    "GECKODRIVER_PATH = \"/usr/local/bin/geckodriver\"  # Adjust as needed\n",
    "\n",
    "# Configure Firefox options\n",
    "options = webdriver.FirefoxOptions()\n",
    "options.binary_location = \"/Applications/Firefox.app/Contents/MacOS/firefox\"\n",
    "# options.add_argument(\"--headless\")  # Optional: Remove this line if you want to see the browser\n",
    "\n",
    "# Start Selenium WebDriver manually\n",
    "service = Service(GECKODRIVER_PATH)\n",
    "driver = webdriver.Firefox(service=service, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env file\n",
    "load_dotenv(\"logins.env\")\n",
    "\n",
    "# Facebook credentials from environment variables\n",
    "fb_email = os.getenv('FACEBOOK_EMAIL')\n",
    "fb_password = os.getenv('FACEBOOK_PASSWORD')\n",
    "\n",
    "# Quick check\n",
    "print(f\"Email loaded: {fb_email is not None}, Password loaded: {fb_password is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCRAPER SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Facebook scraping parameters\n",
    "page_or_group_name = 409901703293362\n",
    "#page_group_or_name = 1996906587229548\n",
    "posts_count = 30\n",
    "browser = \"firefox\"\n",
    "proxy = None\n",
    "timeout = 300\n",
    "headless = False  # Should match WebDriver options, please do this so you can log in\n",
    "isGroup = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN SCRAPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = Facebook_scraper(\n",
    "    page_or_group_name,\n",
    "    posts_count,\n",
    "    browser,\n",
    "    proxy=proxy,\n",
    "    timeout=timeout,\n",
    "    headless=headless,\n",
    "    isGroup=isGroup,\n",
    "    username=fb_email,\n",
    "    password=fb_password\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT INSTRUCTIONS\n",
    "\n",
    "You will NEED to refesh the firefox page that is opened and sign into your account to scrape a private group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = scraper.scrap_to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "  \n",
    "\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "# PJ'S AWESOME SCRAPER\n",
    "\n",
    "i got pissed because timestamps weren't working.\n",
    "\n",
    "the initial parts are what i did to start on the chrome scraping but it got me a little mad when it didn't actually get like half the required posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup: chrome driver, cookies, and facebook group page\n",
    "- loads the local chromedriver and launches chrome\n",
    "- injects saved facebook cookies to skip login\n",
    "- navigates to the target facebook group page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "CHROMEDRIVER_PATH = \"/Users/pjsmaza/Downloads/chromedriver-mac-x64/chromedriver\"\n",
    "COOKIES_PATH = \"fb_cookies.json\"\n",
    "\n",
    "# patch facebook_page_scraper to use our local chromedriver\n",
    "def patched_set_driver_for_browser(self, browser_name):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.binary_location = \"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\"\n",
    "    # options.add_argument(\"--headless\")  # optional\n",
    "\n",
    "    service = Service(CHROMEDRIVER_PATH)\n",
    "    return webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# apply the patch\n",
    "driver_initialization.Initializer.set_driver_for_browser = patched_set_driver_for_browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - code below opens a webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up chrome driver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.binary_location = \"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\"\n",
    "\n",
    "service = Service(CHROMEDRIVER_PATH)\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# load facebook and apply session cookies\n",
    "driver.get(\"https://www.facebook.com/\")\n",
    "time.sleep(3)  # let it load\n",
    "\n",
    "with open(COOKIES_PATH, \"r\") as f:\n",
    "    cookies = json.load(f)\n",
    "    for cookie in cookies:\n",
    "        if \"sameSite\" in cookie:\n",
    "            cookie[\"sameSite\"] = \"Strict\"\n",
    "        try:\n",
    "            driver.add_cookie(cookie)\n",
    "        except Exception as e:\n",
    "            print(\"cookie error:\", cookie.get(\"name\"), e)\n",
    "\n",
    "# go to the target group page\n",
    "driver.get(\"https://www.facebook.com/groups/1996906587229548/\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### actual scraper function\n",
    "\n",
    "#### functions: scroll, scrape posts, and save to csv\n",
    "- scrolls the group page to load posts\n",
    "- extracts author, timestamp, content, reactions, and post url\n",
    "- saves everything to a csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pj's ultimate facebook group scraper v2.2\n",
    "# features:\n",
    "# - author extraction with 4 fallback methods \n",
    "# - relative timestamp conversion (3d → actual date)  \n",
    "# - reaction scraping with 3 different approaches \n",
    "# - error resilience against facebook's nonsense \n",
    "# - clean CSV output \n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 1. SCROLLING MECHANISM\n",
    "# --------------------------\n",
    "def scroll_to_load(driver, max_scrolls=600, wait=2, min_scrolls=60, verbose=True):\n",
    "    \"\"\"scrolls the page with smart detection but ensures a minimum number of scrolls\"\"\"\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    stall_counter = 0\n",
    "\n",
    "    for i in range(max_scrolls):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(wait)\n",
    "\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        # Count visible posts (optional)\n",
    "        posts_found = len(driver.find_elements(By.CSS_SELECTOR, \"div[role='article']\"))\n",
    "        if verbose:\n",
    "            print(f\"Scroll {i+1}/{max_scrolls} | Posts found: {posts_found}\")\n",
    "\n",
    "        # Stop only if we've scrolled at least `min_scrolls`\n",
    "        if new_height == last_height:\n",
    "            stall_counter += 1\n",
    "            if i + 1 >= min_scrolls:\n",
    "                print(\"No new posts detected - stopping scroll\")\n",
    "                break\n",
    "        else:\n",
    "            stall_counter = 0  # reset if progress is made\n",
    "\n",
    "        last_height = new_height\n",
    "\n",
    "# --------------------------\n",
    "# 2. AUTHOR EXTRACTION  \n",
    "# --------------------------\n",
    "def get_author(post):\n",
    "    \"\"\"hunt down author name through 4 different methods\"\"\"\n",
    "    # method 1: standard strong tag (works 60% of the time)\n",
    "    author_elem = post.find(\"span\", {\"dir\": \"auto\"})\n",
    "    if author_elem:\n",
    "        author_strong = author_elem.find(\"strong\")\n",
    "        if author_strong:\n",
    "            return author_strong.get_text(strip=True)\n",
    "\n",
    "    # method 2: aria-label sneak attack\n",
    "    alt_author = post.find(\"a\", {\"aria-label\": True})\n",
    "    if alt_author and len(alt_author[\"aria-label\"]) < 50:  # filter out long aria-labels\n",
    "        return alt_author[\"aria-label\"].strip()\n",
    "\n",
    "    # method 3: role=\"link\" backup\n",
    "    role_author = post.find(\"span\", {\"role\": \"link\"})\n",
    "    if role_author:\n",
    "        text = role_author.get_text(strip=True)\n",
    "        if text and not text.isnumeric():  # filter out random numbers\n",
    "            return text\n",
    "\n",
    "    # method 4: desperate anchor tag grab\n",
    "    fallback = post.find(\"a\")\n",
    "    if fallback:\n",
    "        text = fallback.get_text(strip=True)\n",
    "        if text and len(text) < 30 and not text.startswith((\"http\", \"www\")):  # basic sanity checks\n",
    "            return text\n",
    "\n",
    "    return \"unknown\"  # we tried our best 😔\n",
    "\n",
    "# --------------------------  \n",
    "# 3. TIMESTAMP CONVERSION\n",
    "# --------------------------\n",
    "def get_timestamp(post):\n",
    "    \"\"\"convert facebook's vague time hints into actual dates\"\"\"\n",
    "    time_elem = post.find(\"a\", href=lambda x: x and (\"/posts/\" in x or \"/permalink/\" in x))\n",
    "    if not time_elem:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    timestamp = time_elem.get_text(strip=True)\n",
    "    \n",
    "    # handle \"Just now\" case\n",
    "    if \"Just now\" in timestamp:\n",
    "        return datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    \n",
    "    # extract number and unit\n",
    "    match = re.match(r\"(\\d+)\\s*([smhdwy])\", timestamp)\n",
    "    if not match:\n",
    "        return timestamp  # return as-is if we can't parse\n",
    "    \n",
    "    num, unit = int(match.group(1)), match.group(2)\n",
    "    \n",
    "    # calculate actual datetime\n",
    "    now = datetime.now()\n",
    "    if unit == 's':  # seconds\n",
    "        return (now - timedelta(seconds=num)).strftime(\"%Y-%m-%d %H:%M\")\n",
    "    elif unit == 'm':  # minutes\n",
    "        return (now - timedelta(minutes=num)).strftime(\"%Y-%m-%d %H:%M\") \n",
    "    elif unit == 'h':  # hours\n",
    "        return (now - timedelta(hours=num)).strftime(\"%Y-%m-%d %H:%M\")\n",
    "    elif unit == 'd':  # days\n",
    "        return (now - timedelta(days=num)).strftime(\"%Y-%m-%d\")\n",
    "    elif unit == 'w':  # weeks\n",
    "        return (now - timedelta(weeks=num)).strftime(\"%Y-%m-%d\")\n",
    "    elif unit == 'y':  # years\n",
    "        return (now - timedelta(days=num*365)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    return timestamp  # fallback\n",
    "\n",
    "# --------------------------\n",
    "# 4. REACTION SCRAPING\n",
    "# --------------------------  \n",
    "def get_reactions(post):\n",
    "    \"\"\"count reactions using every trick we know\"\"\"\n",
    "    # method 1: aria-label (most reliable)\n",
    "    reactions_elem = post.find(\"span\", {\"aria-label\": lambda x: x and \"reaction\" in x.lower()})\n",
    "    if reactions_elem:\n",
    "        try:\n",
    "            # extract first number found in aria-label\n",
    "            numbers = re.findall(r'\\d+', reactions_elem[\"aria-label\"])\n",
    "            if numbers:\n",
    "                return int(numbers[0])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # method 2: count reaction emoji images\n",
    "    emoji_container = post.find(\"div\", {\"role\": \"button\"})\n",
    "    if emoji_container:\n",
    "        return len(emoji_container.find_all(\"img\", {\"role\": \"presentation\"}))\n",
    "    \n",
    "    # method 3: look for reaction text\n",
    "    reaction_text = post.find(string=re.compile(r\"Like|Love|Care|Haha|Wow|Sad|Angry\", re.I))\n",
    "    if reaction_text:\n",
    "        return 1  # at least 1 reaction exists\n",
    "    \n",
    "    return 0  # probably no reactions\n",
    "\n",
    "# --------------------------\n",
    "# 5. MAIN EXTRACTION LOGIC\n",
    "# --------------------------\n",
    "def get_content(post):\n",
    "    \"\"\"extract post text with 'See more' expansion\"\"\"\n",
    "    content_div = post.find(\"div\", {\"dir\": \"auto\"})\n",
    "    if not content_div:\n",
    "        return \"\"\n",
    "    \n",
    "    content = content_div.get_text(\"\\n\", strip=True)\n",
    "    \n",
    "    # expand \"See more\" if present\n",
    "    see_more = post.find(\"div\", string=re.compile(r\"See\\s+more\", re.I))\n",
    "    if see_more:\n",
    "        more_text = see_more.find_next(\"div\")\n",
    "        if more_text:\n",
    "            content += \"\\n\" + more_text.get_text(\"\\n\", strip=True)\n",
    "    \n",
    "    return content\n",
    "\n",
    "def get_post_url(post):\n",
    "    \"\"\"extract post URL with fallback\"\"\"\n",
    "    time_elem = post.find(\"a\", href=lambda x: x and (\"/posts/\" in x or \"/permalink/\" in x))\n",
    "    if time_elem:\n",
    "        return urljoin(\"https://www.facebook.com\", time_elem['href'])\n",
    "    return \"unknown\"\n",
    "\n",
    "def extract_posts(driver):\n",
    "    \"\"\"More reliable post detection with Facebook's current layout\"\"\"\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    posts_data = []\n",
    "    \n",
    "    # Try multiple selectors - Facebook changes these frequently\n",
    "    post_selectors = [\n",
    "        {'role': 'article'},  # Standard\n",
    "        {'data-pagelet': re.compile('FeedUnit_')},  # Mobile/new layout\n",
    "        {'class': re.compile('x1yztbdb')}  # Fallback class\n",
    "    ]\n",
    "    \n",
    "    for selector in post_selectors:\n",
    "        posts = soup.find_all(\"div\", selector)\n",
    "        if posts:\n",
    "            break\n",
    "    \n",
    "    for post in posts:\n",
    "        try:\n",
    "            post_data = {\n",
    "                \"author\": get_author(post),\n",
    "                \"timestamp\": get_timestamp(post),\n",
    "                \"content\": get_content(post),\n",
    "                \"post_url\": get_post_url(post),\n",
    "                \"reactions\": get_reactions(post)\n",
    "            }\n",
    "            posts_data.append(post_data)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "            \n",
    "    return posts_data\n",
    "\n",
    "# --------------------------\n",
    "# 6. OUTPUT FUNCTIONS\n",
    "# --------------------------\n",
    "def save_posts_to_csv(posts, filename=\"fb_scraped_data.csv\"):\n",
    "    \"\"\"save our hard-earned data to CSV\"\"\"\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"author\", \"timestamp\", \"content\", \"post_url\", \"reactions\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(posts)\n",
    "\n",
    "# --------------------------\n",
    "# 7. USER-FRIENDLY FILENAME HANDLING\n",
    "# --------------------------\n",
    "def get_output_filename():\n",
    "    \"\"\"get filename from user with smart defaults and validation\"\"\"\n",
    "    while True:\n",
    "        user_input = input(\"Enter output filename (or press Enter for 'fb_scraped_data.csv'): \").strip()\n",
    "        \n",
    "        # Use default if empty\n",
    "        if not user_input:\n",
    "            return \"fb_scraped_data.csv\"\n",
    "        \n",
    "        # Add .csv if missing\n",
    "        if not user_input.lower().endswith('.csv'):\n",
    "            user_input += '.csv'\n",
    "        \n",
    "        # Basic validation\n",
    "        if len(user_input) > 100:\n",
    "            print(\"That filename is too long. Try something shorter.\")\n",
    "            continue\n",
    "            \n",
    "        if not re.match(r'^[\\w\\-\\. ]+$', user_input):\n",
    "            print(\"Invalid characters in filename. Use only letters, numbers, spaces, hyphens, and periods.\")\n",
    "            continue\n",
    "            \n",
    "        return user_input\n",
    "\n",
    "# --------------------------\n",
    "# UPDATED MAIN EXECUTION FLOW\n",
    "# --------------------------\n",
    "def run_scraper(driver):\n",
    "    try:\n",
    "        print(\"🚀 Starting extended Facebook scraper (batch scroll mode)\")\n",
    "        total_scrolls = 600\n",
    "        scrolls_per_batch = 10\n",
    "        total_batches = total_scrolls // scrolls_per_batch\n",
    "        wait = 2.5  # you can bump to 3 if needed\n",
    "\n",
    "        all_posts = {}\n",
    "        last_count = 0\n",
    "        stale_batches = 0\n",
    "\n",
    "        for batch in range(total_batches):\n",
    "            print(f\"Batch {batch+1}/{total_batches} | Scrolling {scrolls_per_batch} times...\")\n",
    "            scroll_to_load(driver, max_scrolls=scrolls_per_batch, wait=wait, verbose=False)\n",
    "            \n",
    "            print(\"🔍 Extracting posts...\")\n",
    "            new_posts = extract_posts(driver)\n",
    "            \n",
    "            new_count = 0\n",
    "            for p in new_posts:\n",
    "                if p[\"post_url\"] not in all_posts:\n",
    "                    all_posts[p[\"post_url\"]] = p\n",
    "                    new_count += 1\n",
    "\n",
    "            total_unique = len(all_posts)\n",
    "            print(f\"New: {new_count} | Total unique: {total_unique}\")\n",
    "\n",
    "            # Early stop if no new posts for 3 consecutive batches\n",
    "            if new_count == 0:\n",
    "                stale_batches += 1\n",
    "                print(f\"⚠️ No new posts in this batch ({stale_batches}x)\")\n",
    "                if stale_batches >= 3:\n",
    "                    print(\"No new content in 3 batches. Stopping early.\")\n",
    "                    break\n",
    "            else:\n",
    "                stale_batches = 0\n",
    "\n",
    "        posts_list = list(all_posts.values())\n",
    "\n",
    "        print(f\"\\n✅ Finished scraping: {len(posts_list)} unique posts\")\n",
    "\n",
    "        if posts_list:\n",
    "            filename = get_output_filename()\n",
    "            save_posts_to_csv(posts_list, filename)\n",
    "            print(f\"Saved {len(posts_list)} posts to '{filename}'\")\n",
    "\n",
    "            # Optional summary\n",
    "            print(\"\\nTop timestamps:\")\n",
    "            df = pd.DataFrame(posts_list)\n",
    "            print(df['timestamp'].value_counts().head(10))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Continuous Scroll Scraper v2.4\n",
      "🔍 Loading posts (this will continue until no new posts appear)...\n",
      "🔄 Scroll 48/300 | Position: 38184px | Posts: 12\n",
      "💤 No new posts detected - stopping at 38184px\n",
      "\n",
      "✨ Found 14 posts total\n",
      "\n",
      "✅ Found 11 unique posts\n"
     ]
    }
   ],
   "source": [
    "run_scraper(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>content</th>\n",
       "      <th>post_url</th>\n",
       "      <th>reactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2025-01-26</td>\n",
       "      <td>Before the lynx was a tree farm what was it? I...</td>\n",
       "      <td>https://www.facebook.com/groups/19969065872295...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10w</td>\n",
       "      <td>2025-01-26</td>\n",
       "      <td>I need help getting the map</td>\n",
       "      <td>https://www.facebook.com/groups/19969065872295...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2025-01-26</td>\n",
       "      <td>Did they buy or were they granted access by th...</td>\n",
       "      <td>https://www.facebook.com/groups/19969065872295...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2025-02-02</td>\n",
       "      <td>Thank you\\nChristina DeGrush\\nI love you</td>\n",
       "      <td>https://www.facebook.com/groups/19969065872295...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2025-02-02</td>\n",
       "      <td>Thank you!</td>\n",
       "      <td>https://www.facebook.com/groups/19969065872295...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2018-04-08</td>\n",
       "      <td>Don't Forget about the old rock ten paper mill...</td>\n",
       "      <td>https://www.facebook.com/groups/19969065872295...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2018-04-08</td>\n",
       "      <td>We all feared there would be a lot of conspira...</td>\n",
       "      <td>https://www.facebook.com/groups/19969065872295...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2018-04-08</td>\n",
       "      <td>Everything seems so obvious. Let’s get this done.</td>\n",
       "      <td>https://www.facebook.com/groups/19969065872295...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2018-04-08</td>\n",
       "      <td>It's Thursday and I won't get down to Micheal'...</td>\n",
       "      <td>https://www.facebook.com/groups/19969065872295...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2018-04-08</td>\n",
       "      <td>Would anyone care if i made this my profile pi...</td>\n",
       "      <td>https://www.facebook.com/groups/19969065872295...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      author   timestamp                                            content  \\\n",
       "0    unknown  2025-01-26  Before the lynx was a tree farm what was it? I...   \n",
       "1        10w  2025-01-26                        I need help getting the map   \n",
       "2    unknown  2025-01-26  Did they buy or were they granted access by th...   \n",
       "3    unknown  2025-02-02           Thank you\\nChristina DeGrush\\nI love you   \n",
       "4    unknown  2025-02-02                                         Thank you!   \n",
       "..       ...         ...                                                ...   \n",
       "252  unknown  2018-04-08  Don't Forget about the old rock ten paper mill...   \n",
       "253  unknown  2018-04-08  We all feared there would be a lot of conspira...   \n",
       "254  unknown  2018-04-08  Everything seems so obvious. Let’s get this done.   \n",
       "255  unknown  2018-04-08  It's Thursday and I won't get down to Micheal'...   \n",
       "256  unknown  2018-04-08  Would anyone care if i made this my profile pi...   \n",
       "\n",
       "                                              post_url  reactions  \n",
       "0    https://www.facebook.com/groups/19969065872295...          0  \n",
       "1    https://www.facebook.com/groups/19969065872295...          0  \n",
       "2    https://www.facebook.com/groups/19969065872295...          0  \n",
       "3    https://www.facebook.com/groups/19969065872295...          0  \n",
       "4    https://www.facebook.com/groups/19969065872295...          0  \n",
       "..                                                 ...        ...  \n",
       "252  https://www.facebook.com/groups/19969065872295...          0  \n",
       "253  https://www.facebook.com/groups/19969065872295...          0  \n",
       "254  https://www.facebook.com/groups/19969065872295...          0  \n",
       "255  https://www.facebook.com/groups/19969065872295...          0  \n",
       "256  https://www.facebook.com/groups/19969065872295...          0  \n",
       "\n",
       "[257 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('otsego_good_maybe.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
