{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uzairname/OtsegoStoryProject/blob/main/experiments/Final_Analysis_Results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sX97uNt4ZBKi",
      "metadata": {
        "id": "sX97uNt4ZBKi"
      },
      "source": [
        "## This notebook works best in Google Colab.\n",
        "If visible, click the \"open in colab\" link to open this notebook in Colab. Otherwise, you must run `pip install -r requirements.txt` before running this notebook.\n",
        "\n",
        "If you would like to view the data, it is available at https://docs.google.com/spreadsheets/d/1WMoeCGweQA0xUtEwlK8R_XzRuZOgPqpHQDGWizb9slQ/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SDRSfp_RMlqU",
      "metadata": {
        "id": "SDRSfp_RMlqU"
      },
      "source": [
        "To be able to use Gemma, follow the instructions that show up after running the cell below to create a hugging face API key, and enter it when prompted.\n",
        "\n",
        "If asked to add the token as a git credential, type n.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ekspuZ_-MMQJ",
      "metadata": {
        "id": "ekspuZ_-MMQJ"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sqo6lfLvrrOh",
      "metadata": {
        "id": "sqo6lfLvrrOh"
      },
      "outputs": [],
      "source": [
        "!pip install -U bertopic bitsandbytes accelerate -q"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8dxVb-PWMUz",
      "metadata": {
        "id": "c8dxVb-PWMUz"
      },
      "source": [
        "# Justice for Otsego Sentiment Analysis\n",
        "\n",
        "This notebook performs sentiment analysis on Facebook posts collected by the Justice for Otsego project using both VADER (lexicon-based) and BERT (transformer-based) approaches.\n",
        "\n",
        "## âœ… How to Reproduce This Notebook\n",
        "\n",
        "To ensure full reproducibility:\n",
        "\n",
        "1. **Environment**  \n",
        "   Use Python 3.8+ with the following packages installed:\n",
        "   - `pandas`\n",
        "   - `matplotlib`\n",
        "   - `nltk`\n",
        "   - `transformers`\n",
        "   - `sklearn`\n",
        "   - `numpy`\n",
        "   - `tqdm`\n",
        "   - `plotly`\n",
        "\n",
        "   You can install these via:\n",
        "   ```bash\n",
        "   pip install pandas matplotlib nltk transformers scikit-learn numpy tqdm plotly"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“Š Preview of Preprocessed Data\n",
        "\n",
        "The following output displays a sample of the original post content (`content`) alongside the cleaned and tokenized version (`cleaned_content`).\n",
        "\n",
        "This step is crucial because:\n",
        "\n",
        "- **Noise Reduction**: Social media posts often contain extra line breaks, emojis, or short fragments. These are removed or cleaned to make the text more analyzable.\n",
        "- **Sentence Filtering**: We only keep sentences with 20 or more characters to avoid processing fragments like \"ugh\" or \"yes,\" which donâ€™t carry much sentiment weight.\n",
        "- **Standardization**: All text is converted to lowercase and stripped of unwanted characters, preserving only punctuation that affects sentence meaning (e.g., `!`, `?`, `.`).\n",
        "- **Readability**: The cleaned version ensures that the models (VADER and BERT) process more meaningful input for sentiment scoring.\n",
        "\n",
        "This table gives us an at-a-glance view of how much transformation the original post undergoes before analysis begins.\n"
      ],
      "metadata": {
        "id": "dqtEoh846CXq"
      },
      "id": "dqtEoh846CXq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaca5acc",
      "metadata": {
        "id": "aaca5acc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from transformers import pipeline\n",
        "from datetime import timedelta\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from tqdm.notebook import tqdm\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Data Loading & Preprocessing\n",
        "# -------------------------------\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Load CSV\n",
        "csv_url = f'https://docs.google.com/spreadsheets/d/1WMoeCGweQA0xUtEwlK8R_XzRuZOgPqpHQDGWizb9slQ/export?format=csv'\n",
        "df = pd.read_csv(csv_url)\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
        "df = df[df['timestamp'].notnull()]  # Remove rows with invalid timestamps\n",
        "df['content'] = df['content'].fillna(\"\").astype(str)\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "    # Replace newlines with a period and a space\n",
        "    text = re.sub(r'[\\r\\n]+', '. ', text)\n",
        "\n",
        "    # Tokenize into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Filter out short sentences\n",
        "    filtered_sentences = [s for s in sentences if len(s) >= 20]\n",
        "\n",
        "    # Remove unwanted characters but preserve punctuation: , \" . ? !\n",
        "    cleaned_sentences = [\n",
        "        re.sub(r'[^a-zA-Z0-9\\s,.!?\\\"\\'â€™]', '', s)\n",
        "        for s in filtered_sentences\n",
        "    ]\n",
        "\n",
        "    # Optionally: lowercase everything for consistency\n",
        "    cleaned_sentences = [s.lower() for s in cleaned_sentences]\n",
        "\n",
        "    return ' '.join(cleaned_sentences)\n",
        "\n",
        "# Remove \"See more\"\n",
        "df['content'] = df['content'].str.replace(\"\\nSee more\", \"\", regex=False)\n",
        "\n",
        "# Apply the preprocessing function to the content column\n",
        "df['cleaned_content'] = df['content'].apply(preprocess_text)\n",
        "\n",
        "# remove empty rows\n",
        "df = df[df['cleaned_content'] != '']\n",
        "\n",
        "# Inspect the first few rows of the new column\n",
        "print(df[['content', 'cleaned_content']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pY7xyu-HOvj2",
      "metadata": {
        "id": "pY7xyu-HOvj2"
      },
      "outputs": [],
      "source": [
        "df[(df['content'].str.len() < 21)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Fy_D_XIUJq8Q",
      "metadata": {
        "id": "Fy_D_XIUJq8Q"
      },
      "source": [
        "### Apply Sentiment Analysis\n",
        "\n",
        "The following cell computes sentiment scores via BERT and Vader. It may take a few minutes\n",
        "\n",
        "## ðŸ’¬ Sentiment Analysis: VADER vs. BERT\n",
        "\n",
        "In this section, we analyze the emotional tone of each Facebook post using **two complementary sentiment analysis models**:\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§  VADER (Valence Aware Dictionary and sEntiment Reasoner)\n",
        "\n",
        "- **What it is**: A lexicon- and rule-based sentiment analysis tool optimized for social media text.\n",
        "- **Why it's used**: It's **fast**, easy to interpret, and works well with shorter, informal text like Facebook posts.\n",
        "- **What it returns**: A `compound` score between -1 (very negative) and +1 (very positive), based on a weighted combination of positive, neutral, and negative word valence.\n",
        "\n",
        "#### Reproducibility Tips:\n",
        "- No randomness in outputs â€” purely deterministic based on text and the internal dictionary.\n",
        "- Requires downloading the `vader_lexicon` once using `nltk.download()`.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ¤– BERT (Bidirectional Encoder Representations from Transformers)\n",
        "\n",
        "- **What it is**: A transformer-based deep learning model trained on a large corpus of human-labeled sentiment data.\n",
        "- **Why it's used**: BERT can detect more **nuanced emotions**, understand **context**, and generally outperforms simpler models on complex or mixed-tone text.\n",
        "- **What it returns**: Labels such as `POSITIVE` or `NEGATIVE` and a confidence `score`.\n",
        "\n",
        "#### How We Convert BERT Output to a Compound Score:\n",
        "- We use a simple transformation:\n",
        "  - `POSITIVE` â†’ +score\n",
        "  - `NEGATIVE` â†’ -score\n",
        "- This allows direct comparison with VADERâ€™s compound score.\n",
        "\n",
        "#### Reproducibility Tips:\n",
        "- BERT models can behave slightly differently across versions or hardware due to floating-point precision.\n",
        "- To ensure stable results:\n",
        "  - Fix the `transformers` version in `requirements.txt`\n",
        "  - Optionally set environment variables like `TRANSFORMERS_NO_ADVISORY_WARNINGS=1` to suppress version warnings.\n",
        "  - Set a fixed random seed if doing advanced fine-tuning or sampling.\n",
        "\n",
        "---\n",
        "\n",
        "### âš–ï¸ Why Both?\n",
        "\n",
        "Using both VADER and BERT gives a **more comprehensive sentiment picture**:\n",
        "- VADER excels at **speed and simplicity**.\n",
        "- BERT provides **depth and context sensitivity**.\n",
        "\n",
        "This dual approach also helps validate whether both models detect similar emotional trends, which boosts confidence in our findings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55016140",
      "metadata": {
        "id": "55016140"
      },
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# 2. Sentiment Analysis: VADER\n",
        "# -------------------------------\n",
        "vader = SentimentIntensityAnalyzer()\n",
        "df['vader_compound'] = df['content'].apply(lambda x: vader.polarity_scores(x)['compound'])\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Sentiment Analysis: BERT\n",
        "# -------------------------------\n",
        "# Initialize a BERT sentiment-analysis pipeline.\n",
        "\n",
        "\n",
        "# bert_pipeline = pipeline(\"text-classification\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "\n",
        "# def get_bert_compound(text):\n",
        "#     # Get the sentiment result (returns a list of dicts)\n",
        "#     result = bert_pipeline(text)\n",
        "#     # Extract the star rating from the label (e.g., \"4 stars\")\n",
        "#     label = result[0]['label']\n",
        "#     rating = int(label.split()[0])\n",
        "#     # Map rating (1-5) to a compound score between -1 and 1:\n",
        "#     # 1 -> -1.0, 2 -> -0.5, 3 -> 0.0, 4 -> 0.5, 5 -> 1.0\n",
        "#     compound = (rating - 3) / 2.0\n",
        "#     return compound\n",
        "\n",
        "\n",
        "# Apply BERT sentiment analysis (this may take a bit, depending on the dataset size)\n",
        "# df['bert_compound'] = df['content'].progress_apply(get_bert_compound)\n",
        "\n",
        "# Load the sentiment analysis pipeline (uses a BERT-based model by default)\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Apply BERT sentiment analysis (this may take a bit, depending on the dataset size)\n",
        "results = sentiment_pipeline(df['content'].tolist(), batch_size=16)\n",
        "\n",
        "compound_scores = [\n",
        "    result['score'] if result['label'] == 'POSITIVE' else -result['score']\n",
        "    for result in results\n",
        "]\n",
        "\n",
        "# Add the new column to the DataFrame\n",
        "df['bert_compound'] = compound_scores\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CU1y5CKSFdbB",
      "metadata": {
        "id": "CU1y5CKSFdbB"
      },
      "outputs": [],
      "source": [
        "vader_dist = pd.cut(df['vader_compound'], bins=[float('-inf'), -0.01, 0.01, float('inf')], labels=['negative', 'neutral', 'positive'], right=True).value_counts()\n",
        "bert_dist = pd.cut(df['bert_compound'], bins=[float('-inf'), -0.7, 0.7, float('inf')], labels=['negative', 'neutral', 'positive'], right=True).value_counts()\n",
        "print('Vader sentiment distribution')\n",
        "print(vader_dist)\n",
        "print('BERT sentiment distribution')\n",
        "print(bert_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "L4eRL9CcFf5p",
      "metadata": {
        "id": "L4eRL9CcFf5p"
      },
      "outputs": [],
      "source": [
        "df['bert_compound'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7WVSI3ypJbF4",
      "metadata": {
        "id": "7WVSI3ypJbF4"
      },
      "source": [
        "# Fit Topic Model\n",
        "\n",
        "The following cells train a topic model on the posts. It assigns a topic index to each post. We can then analyze the posts by topic, date, and sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cogGvM3grprg",
      "metadata": {
        "id": "cogGvM3grprg"
      },
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.cluster import HDBSCAN\n",
        "from bertopic.representation import KeyBERTInspired\n",
        "from umap import UMAP\n",
        "\n",
        "model = BERTopic(\n",
        "    embedding_model=\"all-MiniLM-L6-v2\",\n",
        "    top_n_words=10,\n",
        "    min_topic_size=10,\n",
        "    n_gram_range=(1, 2),\n",
        "    vectorizer_model=CountVectorizer(ngram_range=(1, 2), stop_words=\"english\"),\n",
        "    representation_model=KeyBERTInspired(),\n",
        "    hdbscan_model= HDBSCAN(min_cluster_size=20),\n",
        "    umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine'),\n",
        "    verbose=True,\n",
        "    nr_topics=6,\n",
        ")\n",
        "\n",
        "topics, probs = model.fit_transform(df['cleaned_content'])\n",
        "df['topic'] = topics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1I8ctV2AJETk",
      "metadata": {
        "id": "1I8ctV2AJETk"
      },
      "source": [
        "# Generate Topic Names\n",
        "\n",
        "The following cells will use a language model to assign the topics short titles in natural language. This is a free, open source model from hugging face. It may take a minute to download the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KZj9S2LaCBMr",
      "metadata": {
        "id": "KZj9S2LaCBMr"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# client = OpenAI()\n",
        "# def chat(prompt):\n",
        "#   response = client.responses.create(\n",
        "#       model=\"gpt-4o-mini\",\n",
        "#       input=prompt\n",
        "#   )\n",
        "#.  return response.output_text\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"google/gemma-3-1b-it\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jMhmmwVFJ8Bk",
      "metadata": {
        "id": "jMhmmwVFJ8Bk"
      },
      "outputs": [],
      "source": [
        "def chat(prompt):\n",
        "  from transformers import pipeline\n",
        "\n",
        "  messages = [\n",
        "      {\"role\": \"user\", \"content\": prompt},\n",
        "  ]\n",
        "  output = pipe(messages)\n",
        "  return output[0]['generated_text'][-1]['content']\n",
        "\n",
        "def get_topic_info(model, topic_id, df, n_docs=10):\n",
        "  topic_docs = df[df['topic']==topic_id]\n",
        "  topic_docs = topic_docs.sample(min(n_docs, len(topic_docs)))\n",
        "  keywords = ', '.join([i for i in model.generate_topic_labels(nr_words=5) if int(i.split('_')[0]) == topic_id][0].split('_')[1:])\n",
        "  return topic_docs['content'].tolist(), keywords\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KV4Y_8rHuD4W",
      "metadata": {
        "id": "KV4Y_8rHuD4W"
      },
      "outputs": [],
      "source": [
        "\n",
        "topic_names = {}\n",
        "for topic_id in list(set(model.topics_)):\n",
        "  docs, keywords = get_topic_info(model, topic_id, df)\n",
        "\n",
        "  docs_str = \"\\n\".join(docs)\n",
        "\n",
        "  prompt = docs_str + f\"\\n\\nAbove are a subset of facebook posts that follow a common theme. The theme has the key words \\\"{keywords}\\\". Please come up with a title/label representing the subject of what people are discussing in 5 words or less. Be specific. Respond with just the label and nothing else.\"\n",
        "\n",
        "  print(prompt)\n",
        "\n",
        "  response = chat(prompt)\n",
        "  print(response)\n",
        "\n",
        "  topic_names[topic_id]=response.strip()\n",
        "\n",
        "df['topic_name'] = df['topic'].map(topic_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JvXLs0YAILPp",
      "metadata": {
        "id": "JvXLs0YAILPp"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oImYJyYfvZhb",
      "metadata": {
        "id": "oImYJyYfvZhb"
      },
      "outputs": [],
      "source": [
        "df['topic_name'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YNk5SN9jPM6J",
      "metadata": {
        "id": "YNk5SN9jPM6J"
      },
      "source": [
        "# Figures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5XD3xuD_POpQ",
      "metadata": {
        "id": "5XD3xuD_POpQ"
      },
      "source": [
        "## Sentiment by topic"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“ˆ Sentiment by Topic\n",
        "\n",
        "This bar chart shows the **average sentiment score (using VADER)** for each of the topics identified by BERTopic.\n",
        "\n",
        "### ðŸ§ª What It Shows:\n",
        "\n",
        "- **X-axis (Topic)**: The names or short descriptions of each topic, generated using BERTopic's keyword extraction.\n",
        "- **Y-axis (Mean Sentiment)**: The average VADER compound sentiment score for posts within that topic.\n",
        "  - Values range from -1 (very negative) to +1 (very positive).\n",
        "- **Bar Colors**: Colored by sentiment value to visually emphasize more positive or negative themes.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ” Why This Matters:\n",
        "\n",
        "This visualization helps us understand:\n",
        "- Which topics are generally associated with **positive, neutral, or negative emotions**.\n",
        "- Whether certain issues (e.g., water safety, government response, health symptoms) evoke more emotional responses.\n",
        "- How **emotion and content** are related in community discourse.\n",
        "\n",
        "This is a key step in linking **quantitative emotion data** to **qualitative themes** from the Otsego community's experiences.\n"
      ],
      "metadata": {
        "id": "Yyw3Q9_d6rhl"
      },
      "id": "Yyw3Q9_d6rhl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JeXqj4NbWjOv",
      "metadata": {
        "id": "JeXqj4NbWjOv"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "# Determine mean sentiments by topic\n",
        "sentiment_by_topic = df.groupby(['topic_name']).agg({'vader_compound': 'mean'}).reset_index()\n",
        "\n",
        "fig = px.bar(\n",
        "    sentiment_by_topic,\n",
        "    x='topic_name',\n",
        "    y='vader_compound',\n",
        "    color='vader_compound',\n",
        "    labels={'topic_name': 'Topic', 'vader_compound': \"Mean Sentiment\"},\n",
        "    title='Mean Sentiment by Topic',\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“† Sentiment Trends by Topic Over Time\n",
        "\n",
        "This line plot shows how the **average sentiment** of each topic has changed **year by year** in the Justice for Otsego Facebook posts.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ” What This Chart Tells Us:\n",
        "\n",
        "- **X-axis (Year)**: Time progression based on the year each post was created.\n",
        "- **Y-axis (Mean Sentiment)**: The average VADER sentiment score for posts in each topic during a given year.\n",
        "- **Color-coded Lines**: Each line represents a different topic discovered by BERTopic.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§  Why Itâ€™s Useful:\n",
        "\n",
        "- **Reveals emotional shifts**: Spot years when the community felt more hopeful, upset, or neutral about key issues.\n",
        "- **Tracks community response**: See how public sentiment around certain topics evolved after events like news releases, town halls, or environmental updates.\n",
        "- **Supports storytelling**: Helps frame emotional arcs across time in response to unfolding local crises.\n",
        "\n",
        "This visualization is critical for understanding how **sentiment changes in response to external events** and gives researchers a way to map emotion to real-world context.\n",
        "\n",
        "---\n",
        "\n",
        "**Note**: Since this uses VADER, the sentiment score is between -1 (very negative) and +1 (very positive).\n"
      ],
      "metadata": {
        "id": "f6xWZ_dS6s0i"
      },
      "id": "f6xWZ_dS6s0i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7iuxmB_6Dyca",
      "metadata": {
        "id": "7iuxmB_6Dyca"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Determine mean sentiment by topics over time\n",
        "sentiment_by_topic_year = df.groupby(['topic_name', df['timestamp'].dt.year]).agg({'vader_compound': 'mean'})\n",
        "\n",
        "sentiment_by_topic_year = sentiment_by_topic_year.reset_index()\n",
        "\n",
        "# Create the Plotly line plot\n",
        "fig = px.line(\n",
        "    sentiment_by_topic_year,\n",
        "    x='timestamp',\n",
        "    y=['vader_compound'],\n",
        "    color='topic_name',\n",
        "    title='Mean Sentiment by Topic Over Time',\n",
        "    labels={'timestamp': 'Year', 'value': 'Mean Sentiment', 'topic_name': 'Topic'},\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ§® Volume of Posts by Topic Over Time\n",
        "\n",
        "This line plot illustrates how frequently each topic appeared in the Justice for Otsego Facebook posts, **broken down by year**.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“Š Chart Overview:\n",
        "\n",
        "- **X-axis (Year)**: The year the posts were made, extracted from the `timestamp` column.\n",
        "- **Y-axis (Post Volume)**: The number of posts associated with each topic in that year.\n",
        "- **Color-coded Lines**: Each line represents a different topic identified by BERTopic.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§  Why This is Important:\n",
        "\n",
        "- **Tracks community focus**: Highlights which issues were most frequently discussed in different years.\n",
        "- **Reveals emerging or fading concerns**: For example, a spike might signal a specific event, crisis, or news report that triggered discussion.\n",
        "- **Supports correlation with sentiment**: Helps contextualize the sentiment trends shown in the previous chart â€” a rise in post volume might explain emotional spikes.\n",
        "\n",
        "---\n",
        "\n",
        "By analyzing **volume and sentiment together**, we gain a more complete picture of how community dialogue has evolved, what topics dominated attention, and when public concern was at its highest.\n"
      ],
      "metadata": {
        "id": "WNqa8sCU62BQ"
      },
      "id": "WNqa8sCU62BQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AZlD01QAPlfW",
      "metadata": {
        "id": "AZlD01QAPlfW"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Group by topic and year, then count the number of rows\n",
        "volume_by_topic_year = df.groupby(['topic_name', df['timestamp'].dt.year]).size().reset_index(name='count')\n",
        "\n",
        "# Rename the year column for clarity\n",
        "volume_by_topic_year.rename(columns={'timestamp': 'year'}, inplace=True)\n",
        "\n",
        "# Create the Plotly line plot\n",
        "fig = px.line(\n",
        "    volume_by_topic_year,\n",
        "    x='year',\n",
        "    y='count',\n",
        "    color='topic_name',\n",
        "    title='Volume of Posts by Topic Over Time',\n",
        "    labels={'year': 'Year', 'count': 'Post Volume', 'topic_name': 'Topic'},\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“Š Sentiment Analysis & Forecasting Results\n",
        "\n",
        "This section presents a series of visualizations to better understand the **patterns, differences, and future trends** in community sentiment captured through Facebook posts.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“ˆ 1. Sentiment Trend & Forecast (VADER vs. BERT)\n",
        "\n",
        "Two side-by-side line plots compare **daily average sentiment** over time using:\n",
        "- **VADER** (left): Lexicon-based, interpretable, and fast.\n",
        "- **BERT** (right): Deep-learning-based, context-aware sentiment.\n",
        "\n",
        "Each plot includes:\n",
        "- âš« **Historical sentiment** (dots)\n",
        "- âŒ **Forecasted sentiment** using linear regression (dashed line)\n",
        "- ðŸ“‰ Threshold markers for **Positive (â‰¥ 0.05)**, **Neutral (-0.05 to 0.05)**, and **Negative (â‰¤ -0.05)** tone\n",
        "\n",
        "This lets us explore how sentiment might shift through the end of **2026**, and how each model perceives emotional trends differently.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ” 2. VADER vs. BERT Score Comparison (Scatter Plot)\n",
        "\n",
        "This scatter plot directly compares the **compound sentiment score** of each post as calculated by both models.\n",
        "\n",
        "- Each point = one Facebook post\n",
        "- Red dashed line = perfect agreement between models\n",
        "- Deviations from the line show where **VADER and BERT disagree**\n",
        "\n",
        "This is especially helpful to:\n",
        "- Highlight posts where VADER sees neutral tone but BERT detects strong emotion\n",
        "- Validate consistency between models\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“Š 3. Sentiment Distributions (Histograms)\n",
        "\n",
        "Two side-by-side histograms show how sentiment scores are distributed across all posts for each model:\n",
        "\n",
        "- **VADER** tends to be slightly more conservative, clustering around 0\n",
        "- **BERT** may show stronger positive or negative emotions due to deeper language understanding\n",
        "\n",
        "These plots provide a sense of **emotional polarity** and the overall tone of the dataset.\n",
        "\n",
        "---\n",
        "\n",
        "Together, these visualizations paint a rich picture of:\n",
        "- The emotional state of the Otsego community\n",
        "- How those emotions have evolved\n",
        "- How two different NLP models interpret public sentiment\n",
        "- What might be coming in the future based on trend projections\n"
      ],
      "metadata": {
        "id": "lIf-qXGQ7JiU"
      },
      "id": "lIf-qXGQ7JiU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RRZlokpIzXJF",
      "metadata": {
        "id": "RRZlokpIzXJF"
      },
      "outputs": [],
      "source": [
        "df['date'] = df['timestamp'].dt.date\n",
        "\n",
        "# Aggregate daily average sentiment for VADER and BERT\n",
        "daily_vader = df.groupby('date')['vader_compound'].mean().reset_index().rename(columns={'vader_compound': 'avg_compound'})\n",
        "daily_bert = df.groupby('date')['bert_compound'].mean().reset_index().rename(columns={'bert_compound': 'avg_compound'})\n",
        "\n",
        "# Forecast function using linear regression\n",
        "def forecast_sentiment(daily_df):\n",
        "    # Convert dates to ordinal numbers for regression\n",
        "    daily_df['date_ordinal'] = pd.to_datetime(daily_df['date']).apply(lambda date: date.toordinal())\n",
        "    X = daily_df['date_ordinal'].values.reshape(-1, 1)\n",
        "    y = daily_df['avg_compound'].values\n",
        "    model = LinearRegression()\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Forecast from the day after the last date until the end of 2026\n",
        "    last_date = pd.to_datetime(daily_df['date'].max())\n",
        "    future_dates = pd.date_range(start=last_date + timedelta(days=1), end=pd.Timestamp(\"2026-12-31\"))\n",
        "    future_ordinals = np.array([d.toordinal() for d in future_dates]).reshape(-1, 1)\n",
        "    predicted = model.predict(future_ordinals)\n",
        "    future_df = pd.DataFrame({'date': future_dates, 'predicted_compound': predicted})\n",
        "    return future_df\n",
        "\n",
        "future_vader = forecast_sentiment(daily_vader)\n",
        "future_bert = forecast_sentiment(daily_bert)\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Visualization\n",
        "# -------------------------------\n",
        "\n",
        "# Figure 1: Trend Plots (side-by-side) for VADER and BERT with Forecasts\n",
        "fig, axs = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
        "\n",
        "# VADER Plot\n",
        "axs[0].plot(daily_vader['date'], daily_vader['avg_compound'], marker='o', label='Historical')\n",
        "axs[0].plot(future_vader['date'], future_vader['predicted_compound'], marker='x', linestyle='--', label='Forecast')\n",
        "axs[0].set_xlabel('Date', fontsize=12)\n",
        "axs[0].set_ylabel('Avg Compound Sentiment', fontsize=12)\n",
        "axs[0].set_title('VADER Sentiment Trend & Forecast', fontsize=14)\n",
        "axs[0].set_ylim(-1, 1)\n",
        "axs[0].axhline(y=0.05, color='gray', linestyle='--', linewidth=1)\n",
        "axs[0].axhline(y=-0.05, color='gray', linestyle='--', linewidth=1)\n",
        "axs[0].grid(True)\n",
        "axs[0].legend(fontsize=10)\n",
        "axs[0].text(daily_vader['date'].iloc[-1], 0.07, 'Positive', color='green', fontsize=10)\n",
        "axs[0].text(daily_vader['date'].iloc[-1], 0.00, 'Neutral', color='blue', fontsize=10)\n",
        "axs[0].text(daily_vader['date'].iloc[-1], -0.09, 'Negative', color='red', fontsize=10)\n",
        "\n",
        "# BERT Plot\n",
        "axs[1].plot(daily_bert['date'], daily_bert['avg_compound'], marker='o', label='Historical')\n",
        "axs[1].plot(future_bert['date'], future_bert['predicted_compound'], marker='x', linestyle='--', label='Forecast')\n",
        "axs[1].set_xlabel('Date', fontsize=12)\n",
        "axs[1].set_title('BERT Sentiment Trend & Forecast', fontsize=14)\n",
        "axs[1].set_ylim(-1, 1)\n",
        "axs[1].axhline(y=0.05, color='gray', linestyle='--', linewidth=1)\n",
        "axs[1].axhline(y=-0.05, color='gray', linestyle='--', linewidth=1)\n",
        "axs[1].grid(True)\n",
        "axs[1].legend(fontsize=10)\n",
        "axs[1].text(daily_bert['date'].iloc[-1], 0.07, 'Positive', color='green', fontsize=10)\n",
        "axs[1].text(daily_bert['date'].iloc[-1], 0.00, 'Neutral', color='blue', fontsize=10)\n",
        "axs[1].text(daily_bert['date'].iloc[-1], -0.09, 'Negative', color='red', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Figure 2: Scatter Plot Comparing VADER vs. BERT for Each Post\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df['vader_compound'], df['bert_compound'], alpha=0.6)\n",
        "plt.xlabel('VADER Compound Score', fontsize=12)\n",
        "plt.ylabel('BERT Compound Score', fontsize=12)\n",
        "plt.title('VADER vs. BERT Sentiment Scores', fontsize=14)\n",
        "plt.grid(True)\n",
        "lims = [-1, 1]\n",
        "plt.plot(lims, lims, 'r--', linewidth=1)  # Diagonal reference line\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Figure 3: Histograms of Sentiment Distributions for VADER and BERT\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
        "\n",
        "ax1.hist(df['vader_compound'], bins=20, color='skyblue', edgecolor='black')\n",
        "ax1.set_title('VADER Sentiment Distribution', fontsize=14)\n",
        "ax1.set_xlabel('VADER Compound Score', fontsize=12)\n",
        "ax1.set_ylabel('Frequency', fontsize=12)\n",
        "ax1.set_xlim(-1, 1)\n",
        "ax1.grid(True)\n",
        "\n",
        "ax2.hist(df['bert_compound'], bins=20, color='salmon', edgecolor='black')\n",
        "ax2.set_title('BERT Sentiment Distribution', fontsize=14)\n",
        "ax2.set_xlabel('BERT Compound Score', fontsize=12)\n",
        "ax2.set_xlim(-1, 1)\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Summary Statistics & Analysis Output\n",
        "# -------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“… Additional Visualizations: Weekly Patterns & Statistical Summary\n",
        "\n",
        "To explore **temporal patterns** in sentiment, we break down scores by **day of the week** and analyze overall statistics across the dataset.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“¦ Visualization: Box Plots of Sentiment Scores by Day of Week\n",
        "\n",
        "These two side-by-side box plots show the **distribution of daily sentiment** (VADER and BERT) across the 7 days of the week.\n",
        "\n",
        "- Each box represents the **spread and median** of compound sentiment scores for that day.\n",
        "- Helps identify:\n",
        "  - Are there days where posts are more emotionally intense?\n",
        "  - Do certain days tend to be more negative or positive?\n",
        "\n",
        "This is useful for seeing if emotional tone fluctuates around weekdays/weekends or during heightened activity days (e.g., town halls, news releases).\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“Š Visualization: Stacked Bar Chart of VADER Sentiment Categories by Day\n",
        "\n",
        "This stacked bar chart visualizes the **volume of posts categorized as Positive, Neutral, or Negative** using VADER â€” grouped by day of the week.\n",
        "\n",
        "- Provides a **categorical breakdown** of how emotions are distributed over time.\n",
        "- Useful to identify:\n",
        "  - Which day sees the most negative posts?\n",
        "  - Which days foster positive or neutral discussions?\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“ˆ Summary Statistics\n",
        "\n",
        "A few key statistics help summarize the overall emotional profile of the posts:\n",
        "\n",
        "- **Total posts analyzed**: Gives the dataset scope.\n",
        "- **Average compound score** (VADER and BERT): Measures general tone â€” closer to 0 = more neutral.\n",
        "- **Standard deviation**: Measures variability in emotional tone.\n",
        "- **Sentiment category counts**: How many posts are Positive, Neutral, or Negative.\n",
        "- **Correlation between VADER and BERT scores**:\n",
        "  - Indicates **how aligned the two models are** in their sentiment evaluations.\n",
        "  - A strong positive correlation (close to 1) means consistent scoring.\n",
        "\n",
        "This section supports both a **broad overview** and **granular insights**, combining visual and numeric analysis of the communityâ€™s emotional tone.\n"
      ],
      "metadata": {
        "id": "OhVZUjAF7Mf5"
      },
      "id": "OhVZUjAF7Mf5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cf3ae7e",
      "metadata": {
        "id": "0cf3ae7e"
      },
      "outputs": [],
      "source": [
        "# Additional Visualizations\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Visualization 4: Box Plots of VADER and BERT Compound Scores by Day of Week ---\n",
        "\n",
        "# Create a 'day_of_week' column in the DataFrame with proper ordering\n",
        "days_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
        "df['day_of_week'] = pd.Categorical(df['timestamp'].dt.day_name(), categories=days_order, ordered=True)\n",
        "\n",
        "# Prepare the data lists for each day for both VADER and BERT scores\n",
        "vader_box_data = [df.loc[df['day_of_week'] == day, 'vader_compound'].dropna() for day in days_order]\n",
        "bert_box_data = [df.loc[df['day_of_week'] == day, 'bert_compound'].dropna() for day in days_order]\n",
        "\n",
        "# Create side-by-side box plots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
        "\n",
        "axs[0].boxplot(vader_box_data, labels=days_order)\n",
        "axs[0].set_title(\"VADER Compound Scores by Day of Week\")\n",
        "axs[0].set_xlabel(\"Day of Week\")\n",
        "axs[0].set_ylabel(\"Compound Score\")\n",
        "axs[0].grid(True)\n",
        "\n",
        "axs[1].boxplot(bert_box_data, labels=days_order)\n",
        "axs[1].set_title(\"BERT Compound Scores by Day of Week\")\n",
        "axs[1].set_xlabel(\"Day of Week\")\n",
        "axs[1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --- Visualization 5: Stacked Bar Chart of VADER Sentiment Categories by Day of Week ---\n",
        "\n",
        "# Define a helper function to assign sentiment categories for VADER\n",
        "def categorize(score):\n",
        "    if score >= 0.05:\n",
        "        return 'Positive'\n",
        "    elif score <= -0.05:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Apply the function to create a new category column for VADER scores\n",
        "df['vader_category'] = df['vader_compound'].apply(categorize)\n",
        "\n",
        "# Create a pivot table: counts of sentiment categories by day of week\n",
        "pivot = df.groupby('day_of_week')['vader_category'].value_counts().unstack().fillna(0).loc[days_order]\n",
        "\n",
        "# Plot a stacked bar chart for the VADER sentiment categories by day\n",
        "pivot.plot(kind='bar', stacked=True, figsize=(10, 6), colormap='viridis')\n",
        "plt.title(\"VADER Sentiment Categories by Day of Week\")\n",
        "plt.xlabel(\"Day of Week\")\n",
        "plt.ylabel(\"Number of Posts\")\n",
        "plt.legend(title=\"Sentiment Category\")\n",
        "plt.grid(True, axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Summary Statistics:\")\n",
        "\n",
        "total_posts = len(df)\n",
        "print(f\"Total posts analyzed: {total_posts}\")\n",
        "\n",
        "avg_vader = df['vader_compound'].mean()\n",
        "avg_bert = df['bert_compound'].mean()\n",
        "std_vader = df['vader_compound'].std()\n",
        "std_bert = df['bert_compound'].std()\n",
        "\n",
        "print(f\"Average VADER compound score: {avg_vader:.3f}\")\n",
        "print(f\"Average BERT compound score: {avg_bert:.3f}\")\n",
        "print(f\"Standard Deviation VADER compound score: {std_vader:.3f}\")\n",
        "print(f\"Standard Deviation BERT compound score: {std_bert:.3f}\")\n",
        "\n",
        "# Define a helper function to assign a sentiment category\n",
        "def categorize(score):\n",
        "    if score >= 0.05:\n",
        "        return 'Positive'\n",
        "    elif score <= -0.05:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "vader_categories = df['vader_compound'].apply(categorize)\n",
        "bert_categories = df['bert_compound'].apply(categorize)\n",
        "\n",
        "vader_counts = vader_categories.value_counts()\n",
        "bert_counts = bert_categories.value_counts()\n",
        "\n",
        "print(\"\\nVADER Sentiment Category Counts:\")\n",
        "print(vader_counts)\n",
        "print(\"\\nBERT Sentiment Category Counts:\")\n",
        "print(bert_counts)\n",
        "\n",
        "corr = df['vader_compound'].corr(df['bert_compound'])\n",
        "print(f\"\\nCorrelation between VADER and BERT compound scores: {corr:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "685ddc30",
      "metadata": {
        "id": "685ddc30"
      },
      "source": [
        "## Summary Statistics:\n",
        "\n",
        "- **Total posts analyzed**: 845  \n",
        "- **Average VADER compound score**: 0.079  \n",
        "- **Average BERT compound score**: -0.304  \n",
        "- **Standard Deviation VADER compound score**: 0.452  \n",
        "- **Standard Deviation BERT compound score**: 0.926  \n",
        "\n",
        "---\n",
        "\n",
        "### VADER Sentiment Category Counts:\n",
        "\n",
        "| Sentiment | Count |\n",
        "|-----------|-------|\n",
        "| Positive  | 350   |\n",
        "| Neutral   | 272   |\n",
        "| Negative  | 223   |\n",
        "\n",
        "---\n",
        "\n",
        "### BERT Sentiment Category Counts:\n",
        "\n",
        "| Sentiment | Count |\n",
        "|-----------|-------|\n",
        "| Negative  | 552   |\n",
        "| Positive  | 293   |\n",
        "\n",
        "## Insights & Recommendations\n",
        "- **Context Matters:**  \n",
        "  The slightly positive averages hide variability. BERTâ€™s higher negative count may better reflect community distress.\n",
        "  \n",
        "- **Multiple Methods:**  \n",
        "  Using both VADER and BERT provides a fuller picture. Consider fine-tuning BERT on domain-specific data for improved accuracy.\n",
        "\n",
        "- **Additional Visualizations:**  \n",
        "  - **Heatmaps/Calendar Plots:** Identify periods with heightened negative sentiment.  \n",
        "  - **Topic Modeling:** Use LDA to link themes (e.g., water quality, cancer) with sentiment trends.  \n",
        "  - **Event Annotations:** Overlay key community events on trend graphs to contextualize shifts in sentiment.\n",
        "\n",
        "## Conclusion\n",
        "While overall sentiment appears slightly positive, the variability and methodological differences (especially BERTâ€™s detection of more negative sentiment) suggest that the community's emotional response is more nuanced and polarized. This underscores the need for a combined quantitative and qualitative approach to fully capture the community's experiences, particularly given the serious issues of water quality and health.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}